{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes (Bayes Ingenuo) - Con tunneo de hiperparámetros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carga de datos y preparación de variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Variables predictoras (las mismas que en modelos anteriores)\n",
    "variables_numericas = [\n",
    "    'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF',\n",
    "    '1stFlrSF', 'FullBath', 'YearBuilt', 'KitchenAbvGr',\n",
    "    'TotRmsAbvGrd', 'Fireplaces', 'SalePrice'\n",
    "]\n",
    "\n",
    "df = df[variables_numericas]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definir X (variables predictoras) y \"y\" (variable respuesta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['SalePrice'], axis=1)\n",
    "y = df['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "#### Dividir datos en entrenamienta y prueba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,train_size=0.7, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definir hiperparámetros para el modelo y su pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_grid_naive_bayes =  [{\n",
    "    \"regressor__var_smoothing\": np.logspace(0,-9, num=100)\n",
    "}]\n",
    "\n",
    "numerical_preprocessor = StandardScaler()\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numerical_preprocessor, X.columns)\n",
    "])\n",
    "\n",
    "naive_bayes_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', GaussianNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naïve Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ncast\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('num', StandardScaler(),\n",
      "                                                  Index(['OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', '1stFlrSF',\n",
      "       'FullBath', 'YearBuilt', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces'],\n",
      "      dtype='object'))])),\n",
      "                ('regressor', GaussianNB(var_smoothing=1.0))])\n",
      "best score:\n",
      "-39670.409417066854\n"
     ]
    }
   ],
   "source": [
    "bayes_regressor = GridSearchCV(naive_bayes_pipeline,param_grid=param_grid_naive_bayes,n_jobs=2, cv=5,scoring=\"neg_root_mean_squared_error\")\n",
    "bayes_regressor.fit(X_train, y_train)\n",
    "model = bayes_regressor.best_estimator_\n",
    "print(model)\n",
    "print('best score:')\n",
    "print(bayes_regressor.best_score_)\n",
    "y_mejor_pred = bayes_regressor.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluación de Modelo en Conjunto de Prueba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 26539.12\n",
      "Mean Squared Error (MSE): 1548788039.38\n",
      "Root Mean Squared Error (RMSE): 39354.64\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "mae_nb = mean_absolute_error(y_test, y_mejor_pred)\n",
    "mse_nb = mean_squared_error(y_test, y_mejor_pred)\n",
    "rmse_nb = np.sqrt(mse_nb)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae_nb:.2f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_nb:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse_nb:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "### **Conclusión: Modelo de Regresión (Naïve Bayes)**\n",
    "\n",
    "Después del ajuste de hiperparámetros, el **modelo de regresión basado en Naïve Bayes** mostró una **mejora significativa en todas las métricas** de error:\n",
    "\n",
    "- **MAE** (Error Absoluto Medio) se redujo de **30,461.95** a **26,527.59**, lo que indica que las predicciones son en promedio **casi 4,000 unidades más precisas**.\n",
    "- **MSE** (Error Cuadrático Medio) disminuyó de **2,119,162,831.51** a **1,548,788,039.38**, lo que significa que el modelo produce errores menos extremos.\n",
    "- **RMSE** (Raíz del Error Cuadrático Medio) se redujo de **46,034.37** a **39,354.64**, lo que confirma que los errores de predicción se han reducido en términos generales.\n",
    "\n",
    "**Esto indica que el modelo optimizado tiene una mejor capacidad de generalización y proporciona predicciones más precisas.** La reducción en el RMSE es especialmente importante, ya que refleja que el modelo ahora comete errores **menos severos** al predecir el precio de las casas.\n",
    "\n",
    "### **Conclusión Global**\n",
    "\n",
    "El proceso de **ajuste de hiperparámetros** logró **mejorar ambos modelos**.\n",
    "\n",
    "- En **regresión**, el modelo ahora comete **errores menos graves y predice valores más cercanos a los reales**.\n",
    "- En **clasificación**, el modelo ahora **identifica mejor las clases y reduce la cantidad de errores de categorización**.\n",
    "\n",
    "<small>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
