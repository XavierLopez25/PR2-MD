{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7500572d",
   "metadata": {},
   "source": [
    "# Redes Neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd60e274",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.diagnostic as smd\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "import statsmodels.stats.diagnostic as diag\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "\n",
    "from sklearn.compose import make_column_selector as selector #Para seleccionar de forma automática las variables numéricas y categóricas\n",
    "from sklearn.preprocessing import OneHotEncoder #Para codificar las variables categóricas usando dummies\n",
    "from sklearn.preprocessing import StandardScaler #Para normalizar las variables numéricas\n",
    "from sklearn.compose import ColumnTransformer #Modifica las columnas usando los preprocesadores\n",
    "from sklearn.pipeline import make_pipeline #Planifica una secuencia de procesos\n",
    "from sklearn import set_config #Para mostrar graficamente el pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "set_config(display='diagram')\n",
    "#Metrics\n",
    "from sklearn.metrics import make_scorer, accuracy_score,precision_score, r2_score, mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score ,precision_score,recall_score,f1_score, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3047eb5",
   "metadata": {},
   "source": [
    "#### Lectura de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc2f5713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer los datos\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Selección de variables\n",
    "variables_numericas = [\n",
    "    'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF',\n",
    "    '1stFlrSF', 'FullBath', 'YearBuilt', 'KitchenAbvGr',\n",
    "    'TotRmsAbvGrd', 'Fireplaces', 'SalePrice'\n",
    "]\n",
    "df = df[variables_numericas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "985cb68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SalePrice'] = np.log(df['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "766f076f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['SalePrice'], axis=1)\n",
    "y = df['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f41ad2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test,y_train, y_test = train_test_split(X, y,test_size=0.3,train_size=0.7,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27a27dd",
   "metadata": {},
   "source": [
    "##### División en entrenamiento y prueba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d6d69562",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a4bf0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_r = scaler.fit_transform(X_train)\n",
    "X_test_r = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0b618f",
   "metadata": {},
   "source": [
    "##### Creación de Modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "333af9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\n8nug\\Documents\\Uni\\2025 - 1er Semestre\\Minería de Datos\\PR2-MD\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "c:\\Users\\n8nug\\Documents\\Uni\\2025 - 1er Semestre\\Minería de Datos\\PR2-MD\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "# === Modelo 1 Mejorado: ReLU + adam ===\n",
    "modelo_reg1 = MLPRegressor(\n",
    "    hidden_layer_sizes=(8, 4),\n",
    "    activation='logistic',\n",
    "    solver='lbfgs',  # más preciso en regresión pequeña\n",
    "    learning_rate_init=0.001,\n",
    "    max_iter=1000,\n",
    "    early_stopping=True,\n",
    "    random_state=42,\n",
    "    verbose=True\n",
    ")\n",
    "modelo_reg1.fit(X_train_r, y_train)\n",
    "y_pred_reg1 = modelo_reg1.predict(X_test_r)\n",
    "\n",
    "# === Modelo 2 Mejorado: tanh + lbfgs ===\n",
    "modelo_reg2 = MLPRegressor(\n",
    "    hidden_layer_sizes=(6, 4),\n",
    "    activation='tanh',\n",
    "    solver='lbfgs',  # más preciso en regresión pequeña\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "modelo_reg2.fit(X_train_r, y_train)\n",
    "y_pred_reg2 = modelo_reg2.predict(X_test_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb06a9f",
   "metadata": {},
   "source": [
    "##### Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4ccce358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Resultados - Modelo logistic\n",
      "R² Score       : 0.8277\n",
      "MSE (Error Cuadrático Medio) : 0.03\n",
      "MAE (Error Absoluto Medio)   : 0.11\n",
      "\n",
      "📊 Resultados - Modelo tanh\n",
      "R² Score       : 0.8320\n",
      "MSE (Error Cuadrático Medio) : 0.03\n",
      "MAE (Error Absoluto Medio)   : 0.11\n"
     ]
    }
   ],
   "source": [
    "def evaluar_modelo(y_true, y_pred, nombre):\n",
    "    print(f\"\\n📊 Resultados - {nombre}\")\n",
    "    print(f\"R² Score       : {r2_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"MSE (Error Cuadrático Medio) : {mean_squared_error(y_true, y_pred):.2f}\")\n",
    "    print(f\"MAE (Error Absoluto Medio)   : {mean_absolute_error(y_true, y_pred):.2f}\")\n",
    "\n",
    "evaluar_modelo(y_test, y_pred_reg1, \"Modelo logistic\")\n",
    "evaluar_modelo(y_test, y_pred_reg2, \"Modelo tanh\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
